### 1

mysql5.7之后 mysql_reset_connetion 重置连接资源，并不是断开重连

不建议使用查询缓存，因为存在频繁失效的问题。只要对表有一次更新，就会失效 可以设置参数 query_cache_type 为demand ，按需查询， 需要用到缓存的时候 select SQL_CACHE * from 表名

分析器，识别表名 列命 语法分析
优化器 确定执行方案，索引 执行代价更小 执行器

慢查询中的row_examined 表示扫描的行数

### 2

io成本比较高,每次都写磁盘会很慢 WAL write ahead logging 先写日志，再写磁盘

 redo

 innodb 先写redo log,适当的时候写入磁盘。 redo log固定大小，建议配置4个文件，每个1g.循环写。checkpouit < writepoint 之间是未落盘数据 crash-safe-数据库异常重启，数据不会丢失。从redo log找回数据

binlog 数据库server 特有

为什么两份日志：innodb 后来才有，redo 记录数据页修改了什么。binlog记录的是逻辑日志；redo是循环写，覆盖，binglog是追加写

update: 数据在内存 ，直接更新返回。不在 从磁盘加载到内存 redolog 写入 prepare binlog 写入 red log commit

### 3

redo log保证safe-crash 需要设置参数 innodb_flush_log_at_trx_commit 为1，表示每次写redo log都落盘 sync_binlog 设置为1 每次写binlog都落盘

事务：acid 原子 一致 隔离 持久

串行化，写会加写锁，读会加读锁

事务是如何实现的，读提交和可重复读通过视图实现 读提交，在执行sql的时候创建视图 可重复读，在事务开启的时候创建视图-可重复读

transaction-isolation（设置隔离级别）的值设置READ-COMMITTED

每条更新语句都会记录一个回滚操作。通过回滚可以得到前一个状态的值 不同时刻启动的事务，有不同的read view,同一条记录可能存在多个版本(MVVC)

长事务就意味着更多的版本 视图，更多的存储空间 事务启动：显示启动 begin transaction | set autocommit=0 set autocommit=1 每次事务自动开启提交事务，如果显式 开启事务。 begin transaction with chain 不用每次begin,系统自动begin 省去了begin动作，更简洁 查询长事务 select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60;

### 4

hash索引 只支持等值查询，不支持范围查询 

有序数据只适合静态存储引擎 

二叉树 叶子节点左小右大，顺序排序 n叉树，少回盘，每次多读数据

 非主键索引多一次回表 页分裂，页合并。索引字段越小，占用空间就越小，每次加载到内存的数据就越多 根据业务预估 SET_MAX_EXECUTION_TIME 控制每个语句的最长执行时间 测试阶段general_log 进行查看

### 5

范围查询是查到一条数据后就根据主键回表 如果是主键范围查询也是一条条回表吗

覆盖索引 最左前缀原则 联合索引原则：如果调整顺序可以少维护一个索引，可Kelvin 索引下推 联合索引 A B 查询的时候 like 部分A前缀% and b 5.7之后索引下推

1索引是直接修改；2还是先删除再重建  2好些，可以使索引更紧促，避免数据页有空洞，更省空间

重建主键索引不合理。可以使用 alter table T engine=InnoDB

### 6锁

全局锁 表锁 行锁 全局锁：flush tables with read lock(FTWRL) 整个数据库实例加锁 使数据库只读。做逻辑备份

MYISAM不支持事务，备份需要用到FTWRL

支持事务single-transction innnodb 可以使用 set globle readonly= true只读，不好： 1 主从，判断从节点用的 2发生异常 FTWRL会恢复数据库更新；readonly则不行

DML 增删改数据 DDL修改表结构

表级的锁：表锁 ；元数据锁（meta data lock,MDL） 

表锁：lock table ... read/write unlock tables 释放锁 严格控制： lock table t1 read,t2 write 则在释放锁之前只能对t1读，t2写 不支持t1 写，t2读。很不友好

 MDL:不需要显式使用，访问表的时候自动加上，保证读写正确性。5.5引入 增删改查加MDL读锁，表结构变更加MDL写锁 读锁不互斥；写锁之间互斥 小表加字段，整个库挂了--分析经典 

理想状态：MDL写锁获取加超时机制，获取不到不阻塞后面的操作

INNODB建议使用-single-transaction 参数

### 7

innodb 行锁是在需要的时候才加上，commit之后才会释放。 事务中锁多行，把可能造成锁冲突，影响并发度的锁尽量往后放

死锁和死锁监测 表之间死锁 行之间死锁

 死锁处理：1 innodb_lock_wait_timeout 不友好，如果等待锁资源也有可能超时，误杀 

​					2 innodb_deaklock_detect 设置为on （默认值）死锁检测，回滚其中一个 死锁检测是有代价的，需要检测当前线程有没有被其它线程锁住。 同一行1000并发，需要互相检查100w次，消耗cpu 如何解决：1通过代码保证不会产生死锁，关闭死锁 2控制并发度。有mysql专家 修改源码，对相同行加锁进行排队

同步备份：--经典案例 set session transaction isolation level repeatable read with consitent snapshot

### 8 实验的前提 可重复读---可以回锅

mysql的两个视图 1视图 view,查询语句定义的虚表 create view 2 innodb mvcc一致性读视图。 支持 读提交 和可重复读

快照在mvvc中的工作 可重复读开始，整库快照 每个事务都有一个唯一事务id transaction id ,每行数据也有多个版本，数据更新的时候会生成一个新数据版本，并把transaction id赋值给数据版本的事务id（row trx id）. 同时旧数据版本保留，新版本数据也可以拿到它 语句更新会生成undo log。每个版本的数据可以通过undo log推算上一个版本的数据

所谓整库快照，是说在我启动事务之前已经提交的row_trx_id 对我可见，之后的分情况讨论 innodb 为每个事务构造一个数组，保存事务启动时正在活跃的事务（还没提交）。数组中最小row_trx_id 低水位 最大 row trx id+1记录为高水位 这个视图数组和高水位组成了事务一致性视图

更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。

 当前读：除了update语句外，select 语句如果加锁也是当前读 select ... lock in share model /for update 

读提交和可重复读区别： 1重复读，事务开启创建一致性视图

 2读提交，每个语句执行前都会计算一个新的视图

 start transaction with consistant snapshot 事务开始创建一致性视图，在隔离级别 读提交时没有意义

### 9

等值查询 普通索引是找到下一个不相等的值才停止 唯一索引，找到就ok了，因为唯一，没有必要再往下找了

innodb中每个数据页的大小是16kb 引擎是按页读写的。 如果查询中的普通索引是一页中的最后一个记录，还需要再加载下一页进行判断

更新过程：change buffer 如果要更新的数据在内存中，则直接更新返回。如果不在内存中，等到下一次查询，把数据从磁盘读入内存，然后执行change buffer中的逻辑，叫merge chage buffer

可以拷贝和持久化 meger的几个场景：1访问数据 2数据库关机 3后台定时merge 

merge机制提升系统效率，加载磁盘数据需要占据buffer pool，也避免了内存的占用

 什么时候不使用change buffer 更新完立马获取数据。

唯一索引场景也不适合：change buffer中记录的越多，收益就越高 唯一索引。因为需要校验数据唯一性，必须要回盘。所以只有普通索引可以使用

 插入数据，如果判断的数据不再内存中，唯一索引会加载数据；普通索引不用。高下立见 

change buffer适合写多读少的场景

 change buffer ,redo log 差异总结 redo log 节省的是随机写磁盘 change buffer 节省的是随机读磁盘的io消耗

历史库可以考虑去掉唯一索引

### 10选错索引

set long query time =0;记录所有查询。记录慢查询用的 

索引选错的情况可以手动指定索引 selct * from table force index(a) where a
优化器的逻辑 判断扫描行数 、回表代价、是否使用临时表、是否排序 mysql并不精确的知道要扫描多少行，因为索引数是通过抽样统计出来的，非精准值，会导致判断误差， 精准统计，一行行全表扫描，代价太大 统计索引会选取n个页，统计一个平均值，然后乘以所有的页，得到一个估计值。 数据持续变化，也会导致索引统计量变化，当数据变化量超过1/m时会触发一次索引统计

innodb_stats_persistent

​	on 索引落盘。默认 N:20 M：10 

​	off 只存内存。N 8 M 16 、

show index from 表名  查看一个表上的索引基数 次的索引统计值（cardinality列 执行analyze table t 用来从新统计索引，修正索引统计不准确的情况

索引选择异常和处理

- 1force index.临时方案，不通用，需要改应用，如果数据迁移到其它类型的数据库就不支持了

-  2考虑修改语句 select * from t where a bewteen 100 and 200 and b between 10000 and 20000 order by b limit 1 会选b，是因为优化器使用b可以避免排序，代价更小 如果改为 order by b,a limit 1则这个时候会按照预期选a
-  3某些场景下，可以新建合适的索引，删除误用索引

change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。 

merge过程-总结 

- 1从磁盘读数据 
- 2应用chagne buffer
-  3写redo log 这个数据还在内存中属于脏页，后续会有落盘动作

### 13

表空间：共享和单独
innodb_file_per_table 
off:存共享表空间
on:存.ibd文件
推荐on,5.6之后都是on.删除表的时候可以通过drop table回收表空间

数据删除，并不是真的删了，只是打个标记，这块存储可以被覆盖。删除不会释放空间
如果删除了整个页，则整个页都可以复用了。
如果删除的是中间的记录，不一定能复用，因为b+ 递增
如果数据页数据都比较少，会合并页

删除会造成数据空洞，插入也会
页分裂。去掉空洞，索引紧促。重建表可以达到效果
alter table A engine = Innodb来重建表
流程是 新建一个临时表 数据导入临时表，重命名为重建的表，删除原来的表

mysql5.6引入 online ddL
表重建允许 dml。dml写入内存，ddl 完成后，将内存中的dml应用到表上

analyze table和alter table这三种方式重建表的区别。这里，我顺便再简单和你解释一下。
•从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面图4的流程了；
•analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；
•optimize table t 等于recreate+analyze。

#### 14 count(*)

myisam 是记录一个全局变量
innodb 逐行。不采用myisam方式是因为事务的原因
不要count(主键)会遍历。count(**)优化了的，不取值
count(字段)<count(主键id)<count(1)≈count(**)，

### 15 答疑

binlog完整性验证 
statement 最后会有commit
row格式，最后会有一个xid event

### 16

全字段排序
为每个线程分配内存sort buffer 用来排序
sort_buffer_size来控制排序内存大小
rowid 排序
set max_length_for_sort_data = 16 如果一行数据太长就换一个算法
排序内存只放排序字段
如果内存放不下，则需要借助磁盘

如果内存够，就要多利用内存，尽量减少磁盘访问。
数据天然有序，则不排

### 17 随机

临时表使用的是memory引擎,memory中的引擎可以认为是一个数组，rowid是下标
如果没有主键 mysql会生成rowid

innodb internal_tmp_disk_storage_engine控制

mysql 5.6使用了优先队列排序算法 堆

### 18

隐式转换  字符和数字匹配会转 数字  CAST(tradid AS signed int)
字符编码不一致。向上转换 CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;   utf8mb4是utf8的超集
对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。

### 19

简单查询不返回，很有可能表被锁了
show processlist 查看表的状态
mysql启动时设置 performance_schema=on
则可以select blocking_pid from sys_schema_table_lock_waits 查看哪个线程被阻塞了

flush 被阻塞，也会阻塞后面的操作


读锁引起的阻塞： select * from  sys.innodb_lock_waits where locked_table = test.t \G

当前读的分析-回锅
select from where id=1 ;为什么执行慢
一致性读，是根据undo log推出数据
当前读，是读当前最新数据

### 20 加锁 幻读 - 可以回锅看看场景

幻读：一个事务前后两次查询同一个范围，后一次查询看到前一次查询没有看到的行

1可重复读隔离级别下，普通一致性读是快照读，不会看到 幻读属性
2当前读才会看到幻读数据。幻读专指新插入的行

幻读破坏语义;数据一致性问题  导致数据和日志在逻辑上的一致性

解决幻读：
行锁只能锁行，新插入记录是要更新的记录之间的间隙。
引入间隙锁。两个值之间的间隙

行锁：读锁和读锁之间不冲突；读写之间互斥
间隙锁：间隙锁不冲突，跟间隙锁存在冲突的是往这个间隙中插入一个记录

行锁和间隙锁合称为 next-key lock  前开后闭区间
间隙锁导致锁的范围更大，影响并发度

间隙锁死锁-可以回锅

间隙锁只有的可重复读 隔离级别下才有

读提交情况下，会出现幻读，需要解决数据和日志不一致的问题，需要把
binlog 格式设置为row

读提交隔离界别，语句执行完后只有行锁，且会在语句执行完后把不满足条件的行 行锁去掉

### 21 锁举例-可以回锅

加锁的两个原则 两个优化 一个bug
原则：
1加锁的基本单位是next0key lock  前开后闭
2查找过程中访问过的对象才加锁
优化：
1索引上的等值查询，给唯一索引加锁的时候，next-key lock会退化为行锁
2索引上的等值查询，向右遍历最后一个值不满足等值条件的时候，next-key lock退化为间隙锁
bug:
唯一索引上的范围查询会访问到不满足条件的第一个值为止

在删除数据的时候尽量加limit
读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。

### 22 临时方案

短连接太多，keii 掉不是running状态的连接
show processlist
select * from information_schema.innodb_trx\G

减少连接过程的消耗
跳过数据库权限验证，支持短时间大量连接
-skip-grant-tables
比较危险

慢查询性能：
1索引没有涉及好 2sql没写好 3mysql选错了索引
针对1 紧急创建索引
5.6以后支持online ddl 。高效做法是alter table
老稳妥方案 set sql_log_bing=off

针对2 mysql 5.7提供了query_rewrite sql重写
insert into query_rewrite.rewrite_rules(问题sql,新sql,数据库)
call query_rewrite.flush_rewrite_rules() 是插入规则生效

针对3 临时 force index

qps徒增，功能bug. 从白名单去掉，功能下线。单独库可以删除链接用户；和别的库放在一起可以重写最查勇新能的sql 改为limit 1

### 23 binglog cache 高可用

每个线程都有自己的binlog cache,但共用一份binlog
write 写入page cache
fsync 落盘
sync_binog 参数控制
0：commit只write 不fsync
1每次commit 都fsync
N 每次commit都write,等N个事务后才fsync
如果有io瓶颈可以考虑将N设置100-1000.弊端：突然宕机，丢失事务数据

redo log
redo log先写入redo log buffer(内存) 不需要每次写都落盘
三种状态
1内存中
2写磁盘 page cache中
3fsync 落盘
redo 写入策略 innodb_flush_log_at_trx_commit
0 每次redo log只留在redo log buffer中
1每次redo log提交都落盘
2每次redo log提交只把redo log写入page cache
innodb 后台又线程每隔1秒，把redo log buffer写入page cache，然后fsync落盘


可能会导致没有提交事务的redo log落盘
1redo log满了
2redo log刷盘，顺带把邻居的redo log也落盘了

mysql 组提价的概念   可以回锅
log sequence number LSN
binlog 组提交控制
binlog_group_commit_sync_delay 延迟多少秒才fync
binlog_group_commit_sync_no_delay_count 累积多少次才fync

非双1场景：
1业务高峰
2备库延迟
3备份恢复主库副本
3批量导入

#### 24主备一致-可以回锅

change master
主从复制可以 回锅

binlog三种格式
statement 记录原操作语句，主备索引使用不一致 gtid
row service_id  XID  只记录主键id。记录详细数据。恢复数据比较好
mixed 如果statement不会导致主备不一致则使用statement，否则row
因为row更占空间

分析，还是建议用row, 插入now()会导致主备不一致

循环复制
双主。设置service_id 不同



### 25 binglog cache 高可用

show slave status 查看slave落后master多少秒
seconds_behind_master

主备延迟来源：
1备机性能差导致的
2备库 读压力大
3大事务
4大表DDL

可靠性优先
可用性优先
 数据不一致是因为使用了bin_log_format=mixed 或 format
 如果为row，数据id冲突会报错。更容易暴露出数据不一致的问题

 出现循环复制
 stop slave
 change master to ingore_server_ids = (忽略的service id);
 start slave;

 然后再恢复回来

###  26备库延迟

 mysql 5.6版本之前，slave sql回放只支持 单线程
 sql_thread
 负责读取中转日志和分发
 slave_parallel_workers (32核cpu  8-16最好)

 sql_thread协调者在分发实物的时候必须满足：
 1不能造成更新覆盖。要求同一行的两个事务，必须被分发到同一个worker中
 2同一个事务不能被拆开，必须放到同一个worker中

 按表分发-- 思想比较重要，可以回锅

 mysql 5.7并行复制策略-可以回锅
 slave-parral-type:DATABASE 按库纷发;LOGICAL_CLOCK 

 WRITESET

###  27  主备切换-后续有时间了可以回锅

 设置主动跳过一个事务
 set global sql_slave_skip_counter=1;
 start slave;
 设置跳过特定的错误
 slave_skip_errors
 GTID 	全局事务id
 GTID=service_id:gno
 transaction_id 事务执行的过程中分配的
 gno 事务提交的过程中分配的

 开启gtid gtid_mode=on enforce_gtid_consitencey=on
 set gtid_next=automatic

 mater_auto_position=1表示主备关系使用GTID

###  28 读写分类的坑

 主从 无论如何都有延迟模式
 1强制走主库
 2sleep 一个时间，再去从库拿数据，
 3判断主备无延迟方案
 3配合半同步 semi-sync  只适合一主一从。一主多从，只会接受一个从库返回的ack，其它从库可能并没有最新数据。 持续延迟会导致过度等待
 4等主库位点方案
 5等gtiid 方案

 设置事务更新完后返回 当前事务的gtid. session_track_gtids = OWN_GTID

###  29判断数据库是否出问题

 select 1
 查表判断（如果磁盘满了，不好使）
 更新判断（）
 内部统计

###  30 锁回顾-经典



###  31 误删数据库

 设置sql_safe_updates 

搭建延迟备库

预防误删 库表的方法

### 32 kill 不掉

 kill query + 线程id
 kill connection + 线程id

 kill不动，是因为线程可能还持有着锁，
 kill 
 大事务回滚
 ddl

 客户端连接慢，跟表多有关系。关掉自动补全功能,连接命令加-A 
 -quick的错误使用。
 mysql_store_result 申请内存，结果存储
 mysql_use_result 读一个处理一个,不缓存

 -quick实现的就是第二个效果。
 快在哪里：
 1跳过补全功能
 2mysql_store_result 如果结果打，申请的内存大，影响本地机器性能
 3不会吧执行命令记录到本地命令历史文件

###  33查询数据会不会打爆内存

 取数据和发数据
 1 net_buffer net_buffer_length默认是16k
 2重复获取行 写入net_buffer,满了,通过网络发出。
 网络EAGAIN或WSAEWOULDBLOCK 标识网络栈写满了。socket send buffer


 sending data可能是查询的各个阶段

 innodb buffer pool淘汰数据机制,lru

 inndb 5:3 把整个LRU链表分成young和old区域。--可以回锅

###  34 join

 Index nested-loop join  类似于嵌套查询

 t1 straight_join t2 让mysql使用固定连接方式进行查询，在在前面的是驱动表，后面的是被驱动表
 从t1中取出一行满足条件的数据
 然后遍历t2中的数据进行匹配。

 怎样选择驱动表：
 小表驱动大表。 有索引是log2m
 大表m行 扫描 log2M  N次 N*log2M
 N+N*log2m n越大 越耗时。所以小表驱动大表

 Simple nested-loop join
 如果没有索引，全部全表扫描。实际不会这样处理

 Block Nested-Loop Join
 驱动表上没有索引，走此算法
 join_buffer
 将驱动表满足条件的数据加载到内存中,然后扫描被驱动表和驱动表中的数据进行匹配

 如果驱动表大，则内存加载不下，需要分多次加载到内存.()
 调整join_buffer_size.
 还是小表驱动好，放入内存的次数少

 explain 查看sql  extra block nested loop

 关于小表的定义：符合条件比较少的数据为小表
 如果载入数据一样，哪个有索引，哪个是小表
 如果载入行数相同，载入字段数少的算小表

 在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。

###  35 join优化

 Multi-range read(MRR) 尽量顺序读盘。
 在范围插叙的时候对普通索引关联的主键进行排序,排序完成后，达到顺序读的效果

 1根据普通索引找到主键索引放入到 read_rnd_buffer
 2对read_rnd_buffer进行排序
 3排序后id 进行查询返回

 read_rnd_buffer_size设置缓存大小
 固定使用MRR 需要设置 set optimizer_swith="mrr_cost_based=off"
 官方说法判断消耗更倾向于不使用MRR.通过此设置可以指定使用
 explain 后 extra上是 Uing MRR

 Batched Key Access (5.6之后) BKA算法
 驱动表读一条数据，然后去被驱动表查询，使用不上MRR
 可以一次多从驱动表读数据，放入join_buffer.然后使用MRR

 set optimizer_swith='mrr=on,mrr_cost_based=off,batched_key_access=on'
 BKA是依赖MRR的,索引要启动mrr

 BNL 分析-大表join查询的影响-可以回锅
 buffer_pool
 5（yong）:3(old)分配，表太大，超过一秒，会把查询数据拿到链表头部，
 业务正常访问的数据页，会在old区被淘汰（因为join查询数据太多了，少于1秒的数据
 塞满了old区，需要进行数据淘汰），无法访问到。
 大表join对io的影响是短暂的，查询结束就结束了，对buffer_pool的影响是持续性的，需要依靠后面的
 查询慢慢恢复命中
 影响：
 1多次扫描驱动表
 2join 行m*n此对比
 3导致buffer_pool热数据被淘汰

 BNL转BKA
 直接在被驱动表上建索引，就可以使用BKA
 如果索引加了又比价低频，没有必要加。这个时候可以考虑临时表
 把被驱动表满足条件的数据放入临时表，
 1 t2满足条件数据放入tmp
 2join使用bka算法，给临时表tmp join字段加索引
 3让t1和 tmp做join

 create temporary table temp_t(id int primart key,a int,b int, index(b)) engine=innodb;
 insert into temp_t select * from t2 where b >=1 and b <=2000;
 select * from t1 join temp_t on(t1.b=temp_t.b)

 扩展hash-join （roadmap 目前还未实现）
 直接把两个表的数据查询到 业务代码中，放入hashmap
 然后 从hashmap中找满足的数据。在业务代码层面改进

### 36临时表

 1内存表重启后数据没了，数据在内存中，表结构还在
 2临时表在内存中可以使用各个引擎。数据写在磁盘上，重启肯定都没了

 临时表特性：
 1可以与普通表重名
 2线程隔离
 3一个会话中有同名的临时表和普通表，show create,以及增删改查访问的是临时表
 4show tables 不显示临时表

 临时表做join优化：
 会话结束就删除了。不需要清理数据，自动回收
 不用担心和普通表重名

 分库分表字段的依据，尽量减少夸库跨表查询
 limit group  操作
 1proxy层操作
 2创建临时表，把输入放入临时表，临时表放到某一个库中，进行操作；临时库进行操作

 临时表可以重命名：
 有一个临时文件夹： .frm表结构
 名字是#sql{进程id}_{线程id}_序列号
 数据存储：
 5.6及之前 相同目录.ibd后缀
 5.7及之后 单独临时表空间存储

 物理文件进行区分，内存中也有区分
 table_def_key
 普通表：库名+表名
 临时表： 库名+表明+service_id+thread_id

 每个线程维护自己的临时链表，优先操作临时表。session结束
 对临时表执行 drop temporary table + 表明

 临时表写binlog
 临时表的主备复制。-可以回锅
 row 模式下，备库不会有临时表的操作
 statement mixed会有

 语句改写

 备库是如何处理临时表的，不冲突

 session a table_def_key 在备库体现 库名+t1+M的serviceId+SessionA的thread_id
 session同理
 所以可以实现备库不冲突

###  37临时表

 union执行流程。会去重
 会用到
 t1 放入临时表
 t2遍历获取 匹配数据
 返回数据
 union all 不去重，则不使用临时表，查到数据就返回

 group by
 extra
 using index
 using temporary
 using filesort  需要排序

 不需要排序的场景 可以order by null,跳过排序sort buffer
 tmp_table_size控制临时表的大小。超过大小会转为磁盘存储 

 group by 优化-索引
 数据有序，则不需要临时表和排序
 mysql 5.7 genarated column
 alter table t1 add column z int generated always as(id % 100), add index(z);//修改，不走临时表

 group by优化-直接排序
 不能加索引的情况
 数据比较大，直接走临时磁盘-用的是数组存储
 SQL_BIG_RESULT
 select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;
 MySQL什么时候会使用内部临时表？

1.如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；
2.join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构；
3.如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。

### 38 内存表和普通表的差异

内存表是数组方式存储。堆组织表

不建议生产使用内存表：
1锁粒度。只支持表锁
2数据持久化

临时表使用场景（也可以使用hash索引）



### 39自增主键不连续

表结构保存在.frm文件中
自增主键：
myisam保存在数据文件中
Innodb 保存在内存中，mysql8.0才有了持久化的能力。重后后，从库中查询最大主键值
例如：目前自增是11 ，删除 10重启后又变成 10 了，
mysql8.0 存储在redolog中，靠redo log恢复

自增主键插入 0，null 则走数据库自增
插入具体值，则使用具体值

插入值大于 表现有自增值 则更新为 大的值
否则不变

自增算法：auto_increment_offset 和步长 auto_increment_increment

写入数据的时候，就分配一个自增主键，如果跟表中的唯一索引冲突，则会浪费掉一个
或者更新当前主键为一个已经存在的主键，主键冲突
事务回滚也会导致主键不连续

为什么不把主键改回去：考虑性能问题，不采用回退。
例如：a 2  b 3 b成功了，a失败了改回去成2了，再插入就和3冲突，当然也可以判断是否已经有3了，代价比较大
加锁，有一个在申请主键，则其他事物不允许。并发度降低

自增锁的优化：自增id的锁不是一个事务锁，增完就释放
mysql5.1及之前不是这样的
事务期间锁定，不允许其他事务申请自增主键

5.1.12引入 innodb_autonic_lock_mode 默认为1
自增申请完就释放
insert select 还是等语句后释放。(还有load all)
  考虑到数据一致性问题，所以这里是语句级别的锁。拷贝其它表数据时，自己表又在插入，导致拷贝过来的id和原表不一样了
  解决方式：
  1加语句锁
  2binglog_format = row，记录原始数据。设置 innodb_autonic_lock_mode=2

值为2 申请自增主键的动作都是申请后就释放锁

普通insert valuse 后面多个值，id是可以计算出来的。也是申请一次就释放。
对于无法计算的id值：
第一次申请分配1个
第二次分配2个
4个
依次翻倍。也出现了id不连续

### 40

可重复读
insert select
如果 binlog_format 是statement
会对select 的表加锁

insert select 可以做到不锁全表，只锁需要访问的资源
从t2中最大值加1 插入t1
insert into t2(c,d) (select c+1,d from t force index(c) order by c desc limtit 1);
这个语句只有一个

如果插入自己的话
insert into t(c,d) (select c+1,d from t force index(c) order by c desc limtit 1);
-- 使用到了临时表
先把内容读出来，写入临时表
因为limit 1 所以只从临时表中取一条记录

这个语句全表扫描了。边读边写，可能会读到刚插入的数据，语义不符
可以使用临时表 然后让临时表作为t2进行插入，实现只锁一行

insert 唯一键冲突
认为如果冲突的是主键索引，就加记录锁，唯一索引才加next-key lock。但实际上，这两类索引冲突加的都是next-key lock。
事务里（开启未提交）如果冲突是会加锁的，

insert into ....on dupliacat  key update
主键冲突可以写成 insert into t values(11,10,10) on duplicate key update d=100;
如果冲突就执行后面的更新语句

经典死锁-可以回锅

### 41 怎样最快复制一个表

csv
物理拷贝
 5.6可传输表空间

## 42 grant

mysql.user
acl_user
43要不要使用分区表
partition by range(year(ftime))

### 43分区表

分区表server层人为是同一个表，
mysql第一次打开分区表，会访问所有的分区
server层人为是同一个表，共用一个mdl锁
引擎层，认为是不同的表，mdl锁之后的流程，会根据分区规则，只访问必要的分区

### 44 可以回锅

于MySQL要求主键包含所有的分区字段，所以肯定是要创建联合主键的。



### 45 自增id用完

表自增id 用完后就不变了，可以改成unsigned

innodb自增row_id
如果没有指定主键，会给创建一个6字节的row_id
维护在全局的dict_sys.row_id
超过之后取后6个字节为0
因为原来是8字节，这里是截取操作。插入0,之后再插入
就是1 2  3 。覆盖了原来的数据

xid  server层维护
全局：global_query_id
重启之后请0，事务xid可能相同。重启也会从新生成binlog
达到上限后从0 开始计数。8字节 2 64次方-1
在一个事务中达到上限，基本上不可能

innodb trx_id  
 innodb使用 xid是为了和server层关联起来
 内部维护了一个max_trx_id。每次使用最大+1
 每一行数据记录更新它的trx_id，事务读取数据判断是否可见，是比对一致性视图和trx_id

 正在执行的事务，从information_schema.innodb_trx表中可以看到

 事务id为什么这么大的解释--可以回锅

 达到最大值 2的48次方减1.出现脏读bug. 达到最大上限后，事务id重置为0，其它事务执行的数据
 事务id是一个小的数，导致判断小于低水位线，是合法数据。重启也不会重置事务id，目前是一个bug

 thread_id 自增id
 show processlist中的第一列。大小为4字节。达到上限后重置为0