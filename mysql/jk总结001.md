### 1

mysql5.7之后 mysql_reset_connetion 重置连接资源，并不是断开重连 不建议使用查询缓存，因为存在频繁失效的问题。只要对表有一次更新，就会失效 可以设置参数 query_cache_type 为demand ，按需查询， 需要用到缓存的时候 select SQL_CACHE * from 表名

分析器，识别表名 列命 语法分析
优化器 确定执行方案，索引 执行代价更小 执行器

慢查询中的row_examined 表示扫描的行数

### 2

io成本比较高,每次都写磁盘会很慢 WAL write ahead logging 先写日志，再写磁盘 redo innodb 先写redo log,适当的时候写入磁盘 redo log固定大小，建议配置4个文件，每个1g.循环写。checkpouit < writepoint 之间是未落盘数据 crsh-safe-数据库异常重启，数据不会丢失。从redo log找回数据

binlog 数据库server 特有

为什么两份日志：innodb 后来才有，redo 记录数据页修改了什么。binlog记录的是逻辑日志；redo是循环写，覆盖，binglog是追加写

update: 数据在内存 ，直接更新返回。不在 从磁盘加载到内存 redolog 写入 prepare binlog 写入 red log commit

### 3

redo log保证safe-crash 需要设置参数 innodb_flush_log_at_trx_commit 为1，表示每次写redo log都落盘 sync_binlog 设置为1 每次写binlog都落盘

事务：acid 原子 一致 隔离 持久

串行化，写会加写锁，读会加读锁

事务是如何实现的，读提交和可重复读通过视图实现 读提交，在执行sql的时候创建视图 可重复读，在事务开启的时候创建视图

transaction-isolation（设置隔离级别）的值设置READ-COMMITTED

每条更新语句都会记录一个回滚操作。通过回滚可以得到前一个状态的值 不同时刻启动的事务，有不同的read view,同一条记录可能存在多个版本(MVVC)

长事务就意味着更多的版本 视图，更多的存储空间 事务启动：显示启动 begin transaction | set autocommit=0 set autocommit=1 每次事务自动开启提交事务，如果显式 开启事务。 begin transaction with chain 不用每次begin,系统自动begin 省去了begin动作，更简洁 查询长事务 select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60;

### 4

hash索引 只支持等值查询，不支持范围查询 有序数据只适合静态存储引擎 二叉树 叶子节点左小右大，顺序排序 n叉树，少回盘，每次多多数据 非主键索引多一次回表 页分裂，页合并。索引字段越小，占用空间就越小，每次加载到内存的数据就越多 根据业务预估 SET_MAX_EXECUTION_TIME 控制每个语句的最长执行时间 测试阶段general_log 进行查看

### 5

范围查询是查到一条数据后就根据主键回表 如果是主键范围查询也是一条条回表吗

覆盖索引 最左前缀原则 联合索引原则：如果调整顺序可以少维护一个索引，可Kelvin 索引下推 联合索引 A B 查询的时候 like 部分A前缀% and b 5.7之后索引下推

1索引是直接修改；2还是先删除再重检 2好些，可以使索引更紧促，避免数据页有空洞，更省空间

重建主键索引不合理。可以使用 alter table T engine=InnoDB

### 6锁

全局锁 表锁 行锁 全局锁：flush tables with read lock(FTWRL) 整个数据库实例加锁 使数据库只读。做逻辑备份

MYISAM不支持事务，备份需要用到FTWRL

支持事务single-transction innnodb 可以使用 set globle readonly= true只读，不好： 1 主从，判断从节点用的 2发生异常 FTWRL会恢复数据库更新；readonly则不行

DML 增删改数据 DDL修改表结构

表级的锁：表锁 ；元数据锁（meta data lock,MDL） 表锁：lock table ... read/write unlock tables 释放锁 严格控制： lock table t1 read,t2 write 则在释放锁之前之鞥呢对t1读，t2写 不支持t1 写，t2读。很不友好 MDL:不需要显式使用，访问表的时候自动加上，保证读写正确性。5.5引入 增删改查加MDL读锁，表结构变更加MDL写锁 读锁不互斥；写锁之间互斥 小表加字段，整个库挂了--分析经典 理想状态：MDL写锁获取加超时机制，获取不到不阻塞后面的操作

INNODB建议使用-single-transaction 参数

### 7

innodb 行锁是在需要的时候才加上，commit之后才会释放。 事务中锁多行，把可能造成锁冲突，影响并发度的锁尽量往后放

死锁和死锁监测 表之间死锁 行之间死锁 死锁处理：1 innodb_lock_wait_timeout 不友好，如果等待锁资源也有可能超时，误杀 2 innodb_deaklock_detect 设置为on （默认值）死锁检测，回滚其中一个 死锁检测是有代价的，需要检测当前线程有没有被其它线程锁住。 同一行1000并发，需要互相检查100w此，消耗cpu 如何解决：1通过代码保证不会产生死锁，关闭死锁 2控制并发度。有mysql专家 修改源码，对相同行加锁进行排队

同步备份：--经典案例 set session transaction isolation level repeatable read with consitent snapshot

### 8 实验的前提 可重复读---可以回锅

mysql的两个视图 1视图 view,查询语句定义的续表 create view 2 innodb mvcc一致性读视图。 支持 读提交 和可重复读

快照在mvvc中的工作 可重复读开始，整库快照 每个事务都有一个唯一事务id transaction id 每行数据也有多个版本，数据更新的时候会生成一个新数据版本，并把transaction id赋值给数据版本的事务id（row trx id）. 同时旧数据版本保留，新版本数据也可以拿到它 语句更新会生成undo log。每个版本的数据可以通过undo log推算上一个版本的数据

所谓整库快照，是说在我启动事务之前已经提交的row_trx_id 对我可见，之后的分情况讨论 innodb 为每个事务构造一个数组，保存事务启动时正在活跃的事务（还没提交）。数组中最小row_trx_id 低水位 最大 row trx id+1记录为高水位 这个视图数组和高水位组成了事务一致性视图

更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。 当前读：除了update语句外，select 语句如果加锁也是当前读 select ... lock in share model /for update 读提交和可重复读区别： 1重复读，事务开启创建一致性视图 2读提交，每个语句执行前都会计算一个新的视图 start transaction with consistant snapshot 事务开始创建一致性视图，在隔离级别 读提交时没有意义

### 9

等值查询 普通索引是找到下一个不相等的值才停止 唯一索引，找到就ok了，因为唯一，没有必要再往下找了

innodb中每个数据页的大小是16kb 引擎是按页读写的。 如果查询中的普通索引是一页中的最后一个记录，还需要再加载下一页进行判断

更新过程：change buffer 如果要更新的数据在内存中，则直接更新返回。等到下一次查询，把数据从磁盘读入内存，然后执行change buffer中的逻辑，叫merge chage buffer可以拷贝和持久化 meger的几个场景：1访问数据 2数据库关机 3后台定时merge merge机制提升系统效率，加载磁盘数据需要占据buffer pool，也避免了内存的占用 什么时候不使用change buffer 更新完立马获取数据-普通索引场景也不适合。change buffer中记录的越多，收益就越高 唯一索引。因为需要校验数据唯一性，必须要回盘。所以只用普通索引可以使用 插入数据，如果判断的数据不再内存中，唯一索引会加载数据；普通索引不用。高下立见 change buffer适合写多读少的场景 change buffer ,redo log 差异总结 redo log 节省的是随机写磁盘 change buffer 节省的是随机读磁盘的io消耗

历史库可以考虑去掉唯一索引

### 10选错索引

set long query time =0;记录所有查询。记录慢查询用的 索引选错的情况可以手动指定索引 selct * from table force index(a) where a
优化器的逻辑 判断扫描行数 、回表代价、是否使用临时表、是否排序 mysql并不精确的知道要扫描多少行，因为索引数是通过抽样统计出来的，非精准值，会导致判断误差， 精准统计，一行行全表扫描，代价太大 统计索引会选取n个页，统计一个平均值，然后乘以所有的页，得到一个估计值。 数据持续变化，也会导致索引统计量变化，当数据变化量超过1/m时会触发一次索引统计

innodb_stats_persistent on 索引落盘。默认 N:20 M：10 off 只存内存。N 8 M 16 show index from table 查看一个表上的索引基数 次的索引统计值（cardinality列 执行analyze table t 用来从新统计索引，修正索引统计不准确的情况

索引选择异常和处理 1force index.临时方案，不通用，需要改应用，如果数据迁移就不支持了 2考虑修改语句 select * from t where a bewteen 100 and 200 and b between 10000 and 20000 order by b limit 1 会选b，是因为优化使用b可以避免排序，代价更小 如果改为 order by b,a limit 1则这个时候会按照预期选a 3某些场景下，可以新建合适的索引，删除误用索引

change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。 merge过程-总结 1从磁盘读数据 2应用chagne buffer 3写redo log 这个数据还在内存中属于脏页，后续会有落盘动作

### 13

表空间：共享和单独
innodb_file_per_table 
off:存共享表空间
on:存.ibd文件
推荐on,5.6之后都是on.删除表的时候可以通过drop table回收表空间

数据删除，并不是真的删了，只是打个标记，这块存储可以被覆盖。删除不会释放空间
如果删除了整个页，则整个页都可以复用了。
如果删除的是中间的记录，不一定能复用，因为b+ 递增
如果数据页数据都比较少，会合并页

删除会造成数据空洞，插入也会
页分裂。去掉空洞，索引紧促。重建表可以达到效果
alter table A engine = Innodb来重建表
流程是 新建一个临时表 数据导入临时表，重命名为重建的表，删除原来的表

mysql5.6引入 online ddL
表重建允许 dml

analyze table和alter table这三种方式重建表的区别。这里，我顺便再简单和你解释一下。
•从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面图4的流程了；
•analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；
•optimize table t 等于recreate+analyze。

#### 14 count(*)

myisam 是记录一个全局变量
innodb 逐行。不采用myisam方式是因为事务的原因
不要count(主键)会遍历。count(*)优化了的，不取值
count(字段)<count(主键id)<count(1)≈count(*)，

### 15 答疑

binlog完整性验证 
statement 最后会有commit
row格式，最后会有一个xid event

### 16

全字段排序
为每个线程分配内存sort buffer 用来排序
sort_buffer_size来控制排序内存大小
rowid 排序
set max_length_for_sort_data = 16 如果一行数据太长就换一个算法
排序内存只放排序字段
如果内存放不下，则需要借助磁盘

如果内存够，就要多利用内存，尽量减少磁盘访问。
数据天然有序，则不排

### 17 随机

临时表使用的是memory引擎,memory中的引擎可以人为是一个数组，rowid是下标
如果没有主键 mysql会生成rowid

innodb internal_tmp_disk_storage_engine控制

mysql 5.6使用了优先队列排序算法 堆

### 18

隐式转换  字符和数字匹配会转 数字  CAST(tradid AS signed int)
字符编码不一致。向上转换 CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;   utf8mb4是utf8的超集
对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。

### 19

简单查询不返回，很有可能表被锁了
show processlist 查看表的状态
mysql启动时设置 performance_schema=on
则可以select blocking_pid from sys_schema_table_lock_waits 查看哪个线程被阻塞了

flush 被阻塞，也会阻塞后面的操作


读锁引起的阻塞： select * from  sys.innodb_lock_waits where locked_table = test.t \G

当前读的分析-回锅
select from where id=1 ;为什么执行慢
一致性读，是根据undo log推出数据
当前读，是读当前最新数据

### 20 加锁 幻读 - 可以回锅看看场景

幻读：一个事务前后两次查询同一个范围，后一次查询看到前一次查询没有看到的行

1可重复读隔离级别下，普通一致性读是快照读，不会看到 幻读属性
2当前读才会看到幻读数据。幻读专指新插入的行

幻读破坏语义;数据一致性问题  导致数据和日志在逻辑上的一致性

解决幻读：
行锁只能锁行，新插入记录是要更新的记录之间的间隙。
引入间隙锁。两个值之间的间隙

行锁：读锁和读锁之间不冲突；读写之间互斥
间隙锁：间隙锁不冲突，跟间隙锁存在冲突的是往这个间隙中插入一个记录

行锁和间隙锁合称为 next-key lock  前开后闭区间
间隙锁导致锁的范围更大，影响并发度

间隙锁死锁-可以回锅

间隙锁只有的可重复读 隔离级别下才有

读提交情况下，会出现幻读，需要解决数据和日志不一致的问题，需要把
binlog 格式设置为row

读提交隔离界别，语句执行完后只有行锁，且会在语句执行完后把不满足条件的行 行锁去掉

### 21 锁举例-可以回锅

加锁的两个原则 两个优化 一个bug
原则：
1加锁的基本单位是next0key lock  前开后闭
2查找过程中访问过的对象才加锁
优化：
1索引上的等值查询，给唯一索引加锁的时候，next-key lock会退化为行锁
2索引上的等值查询，向右遍历最后一个值不满足等值条件的时候，next-key lock退化为间隙锁
bug:
唯一索引上的范围查询会访问到不满足条件的第一个值为止

在删除数据的时候尽量加limit
读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。

### 22 临时方案

短连接太多，keii 掉不是running状态的连接
show processlist
select * from information_schema.innodb_trx\G

减少连接过程的消耗
跳过数据库权限验证，支持短时间大量连接
-skip-grant-tables
比较危险

慢查询性能：
1索引没有涉及好 2sql没写好 3mysql选错了索引
针对1 紧急创建索引
5.6以后支持online ddl 。高效做法是alter table
老稳妥方案 set sql_log_bing=off

针对2 mysql 5.7提供了query_rewrite sql重写
insert into query_rewrite.rewrite_rules(问题sql,新sql,数据库)
call query_rewrite.flush_rewrite_rules() 是插入规则生效

针对3 临时 force index

qps徒增，功能bug. 从白名单去掉，功能下线。单独库可以删除链接用户；和别的库放在一起可以重写最查勇新能的sql 改为limit 1

### 23 binglog cache 高可用

每个线程都有自己的binlog cache,但共用一份binlog
write 写入page cache
fsync 落盘
sync_binog 参数控制
0：commit只write 不fsync
1每次commit 都fsync
N 每次commit都write,等N个事务后才fsync
如果有io瓶颈可以考虑将N设置100-1000.弊端：突然宕机，丢失事务数据

redo log
redo log先写入redo log buffer(内存) 不需要每次写都落盘
三种状态
1内存中
2写磁盘 page cache中
3fsync 落盘
redo 写入策略 innodb_flush_log_at_trx_commit
0 每次redo log只留在redo log buffer中
1每次redo log提交都落盘
2每次redo log提交只把redo log写入page cache
innodb 后台又线程每隔1秒，把redo log buffer写入page cache，然后fsync落盘


可能会导致没有提交事务的redo log落盘
1redo log满了
2redo log刷盘，顺带把邻居的redo log也落盘了

mysql 组提价的概念   可以回锅
log sequence number LSN
binlog 组提交控制
binlog_group_commit_sync_delay 延迟多少秒才fync
binlog_group_commit_sync_no_delay_count 累积多少次才fync

非双1场景：
1业务高峰
2备库延迟
3备份恢复主库副本
3批量导入

#### 24主备一致-可以回锅

change master
主从复制可以 回锅

binlog三种格式
statement 记录原操作语句，主备索引使用不一致 gtid
row service_id  XID  只记录主键id。记录详细数据。恢复数据比较好
mixed 如果statement不会导致主备不一致则使用statement，否则row
因为row更占空间

分析，还是建议用row, 插入now()会导致主备不一致

循环复制
双主。设置service_id 不同



### 25 binglog cache 高可用

show slave status 查看slave落后master多少秒
seconds_behind_master

主备延迟来源：
1备机性能差导致的
2备库 读压力大
3大事务
4大表DDL

可靠性优先
可用性优先
 数据不一致是因为使用了bin_log_format=mixed
 如果为row，数据id冲突会报错