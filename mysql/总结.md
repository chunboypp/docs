### 1

mysql5.7之后 mysql_reset_connetion 重置连接资源，并不是断开重连
不建议使用查询缓存，因为存在频繁失效的问题。只要对表有一次更新，就会失效
可以设置参数 query_cache_type 为demand ，按需查询，
需要用到缓存的时候 select SQL_CACHE * from 表名

分析器，识别表名 列命 语法分析  
优化器 确定执行方案，索引 执行代价更小
执行器

慢查询中的row_examined 表示扫描的行数

### 2

io成本比较高,每次都写磁盘会很慢
WAL write ahead logging 先写日志，再写磁盘
redo innodb 先写redo log,适当的时候写入磁盘
redo log固定大小，建议配置4个文件，每个1g.循环写。checkpouit  < writepoint 之间是未落盘数据
 crsh-safe-数据库异常重启，数据不会丢失。从redo log找回数据

binlog 数据库server 特有

为什么两份日志：innodb 后来才有，redo 记录数据页修改了什么。binlog记录的是逻辑日志；redo是循环写，覆盖，binglog是追加写

update: 数据在内存 ，直接更新返回。不在 从磁盘加载到内存
	redolog 写入 prepare  binlog 写入 red log commit

### 3

redo log保证safe-crash 需要设置参数 innodb_flush_log_at_trx_commit 为1，表示每次写redo log都落盘
sync_binlog 设置为1 每次写binlog都落盘

事务：acid 原子 一致 隔离 持久

串行化，写会加写锁，读会加读锁

事务是如何实现的，读提交和可重复读通过视图实现
	读提交，在执行sql的时候创建视图
	可重复读，在事务开启的时候创建视图

transaction-isolation（设置隔离级别）的值设置READ-COMMITTED

每条更新语句都会记录一个回滚操作。通过回滚可以得到前一个状态的值
	不同时刻启动的事务，有不同的read view,同一条记录可能存在多个版本(MVVC)

长事务就意味着更多的版本 视图，更多的存储空间
事务启动：显示启动 begin transaction | set autocommit=0
set autocommit=1 每次事务自动开启提交事务，如果显式 开启事务。
begin transaction with chain 不用每次begin,系统自动begin 省去了begin动作，更简洁
查询长事务
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60;

### 4

hash索引 只支持等值查询，不支持范围查询
有序数据只适合静态存储引擎
二叉树 叶子节点左小右大，顺序排序
n叉树，少回盘，每次多多数据
非主键索引多一次回表
页分裂，页合并。索引字段越小，占用空间就越小，每次加载到内存的数据就越多
根据业务预估 SET_MAX_EXECUTION_TIME 控制每个语句的最长执行时间
测试阶段general_log 进行查看

### 5

范围查询是查到一条数据后就根据主键回表
如果是主键范围查询也是一条条回表吗

覆盖索引
最左前缀原则
联合索引原则：如果调整顺序可以少维护一个索引，可Kelvin
索引下推  联合索引 A B 
查询的时候 like 部分A前缀% and b 5.7之后索引下推

1索引是直接修改；2还是先删除再重检
2好些，可以使索引更紧促，避免数据页有空洞，更省空间

重建主键索引不合理。可以使用 alter table T engine=InnoDB

### 6锁

全局锁 表锁 行锁
全局锁：flush tables with read lock(FTWRL) 整个数据库实例加锁
	使数据库只读。做逻辑备份
	
MYISAM不支持事务，备份需要用到FTWRL

支持事务single-transction innnodb
可以使用 set globle readonly= true只读，不好：
1 主从，判断从节点用的
2发生异常 FTWRL会恢复数据库更新；readonly则不行

DML 增删改数据 DDL修改表结构

表级的锁：表锁 ；元数据锁（meta data lock,MDL）
表锁：lock table ... read/write
unlock tables 释放锁
严格控制： lock table t1 read,t2 write 则在释放锁之前之鞥呢对t1读，t2写
不支持t1 写，t2读。很不友好
MDL:不需要显式使用，访问表的时候自动加上，保证读写正确性。5.5引入
增删改查加MDL读锁，表结构变更加MDL写锁
读锁不互斥；写锁之间互斥
小表加字段，整个库挂了--分析经典
理想状态：MDL写锁获取加超时机制，获取不到不阻塞后面的操作

INNODB建议使用-single-transaction 参数

### 7


innodb 行锁是在需要的时候才加上，commit之后才会释放。
事务中锁多行，把可能造成锁冲突，影响并发度的锁尽量往后放

死锁和死锁监测
表之间死锁
行之间死锁
死锁处理：1 innodb_lock_wait_timeout 不友好，如果等待锁资源也有可能超时，误杀
2 innodb_deaklock_detect 设置为on （默认值）死锁检测，回滚其中一个
死锁检测是有代价的，需要检测当前线程有没有被其它线程锁住。
同一行1000并发，需要互相检查100w此，消耗cpu
如何解决：1通过代码保证不会产生死锁，关闭死锁
2控制并发度。有mysql专家 修改源码，对相同行加锁进行排队

同步备份：--经典案例
set session transaction isolation level repeatable read
with consitent snapshot

### 8 实验的前提 可重复读---可以回锅

mysql的两个视图
1视图 view,查询语句定义的续表 create view 
2 innodb mvcc一致性读视图。
支持 读提交 和可重复读

快照在mvvc中的工作
可重复读开始，整库快照
每个事务都有一个唯一事务id transaction id
每行数据也有多个版本，数据更新的时候会生成一个新数据版本，并把transaction id赋值给数据版本的事务id（row trx id）.
	同时旧数据版本保留，新版本数据也可以拿到它
语句更新会生成undo log。每个版本的数据可以通过undo log推算上一个版本的数据

所谓整库快照，是说在我启动事务之前已经提交的row_trx_id 对我可见，之后的分情况讨论
innodb 为每个事务构造一个数组，保存事务启动时正在活跃的事务（还没提交）。数组中最小row_trx_id 低水位 最大 row trx id+1记录为高水位
这个视图数组和高水位组成了事务一致性视图

更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。
当前读：除了update语句外，select 语句如果加锁也是当前读 select ... lock in share model /for update
读提交和可重复读区别：
	1重复读，事务开启创建一致性视图
	2读提交，每个语句执行前都会计算一个新的视图
	start transaction with consistant snapshot 事务开始创建一致性视图，在隔离级别 读提交时没有意义

### 9

等值查询
普通索引是找到下一个不相等的值才停止
唯一索引，找到就ok了，因为唯一，没有必要再往下找了

innodb中每个数据页的大小是16kb
引擎是按页读写的。
如果查询中的普通索引是一页中的最后一个记录，还需要再加载下一页进行判断

更新过程：change buffer
	如果要更新的数据在内存中，则直接更新返回。等到下一次查询，把数据从磁盘读入内存，然后执行change buffer中的逻辑，叫merge
	chage buffer可以拷贝和持久化
	meger的几个场景：1访问数据 2数据库关机 3后台定时merge
	merge机制提升系统效率，加载磁盘数据需要占据buffer pool，也避免了内存的占用
什么时候不使用change buffer
	更新完立马获取数据-普通索引场景也不适合。change buffer中记录的越多，收益就越高
	唯一索引。因为需要校验数据唯一性，必须要回盘。所以只用普通索引可以使用
插入数据，如果判断的数据不再内存中，唯一索引会加载数据；普通索引不用。高下立见
change buffer适合写多读少的场景
change buffer ,redo log 差异总结
 redo log 节省的是随机写磁盘
 change buffer 节省的是随机读磁盘的io消耗

 历史库可以考虑去掉唯一索引

### 10选错索引

set long query time =0;记录所有查询。记录慢查询用的
索引选错的情况可以手动指定索引 selct * from table force index(a) where a  
优化器的逻辑
 判断扫描行数 、回表代价、是否使用临时表、是否排序
 mysql并不精确的知道要扫描多少行，因为索引数是通过抽样统计出来的，非精准值，会导致判断误差，
 精准统计，一行行全表扫描，代价太大
 统计索引会选取n个页，统计一个平均值，然后乘以所有的页，得到一个估计值。
 数据持续变化，也会导致索引统计量变化，当数据变化量超过1/m时会触发一次索引统计

 innodb_stats_persistent
  on 索引落盘。默认 N:20 M：10
  off 只存内存。N 8 M 16
 show index from table 查看一个表上的索引基数
 次的索引统计值（cardinality列
 执行analyze table t 用来从新统计索引，修正索引统计不准确的情况

 索引选择异常和处理
 1force index.临时方案，不通用，需要改应用，如果数据迁移就不支持了
 2考虑修改语句 select * from t where a bewteen 100 and 200 and b between 10000 and 20000 order by b limit 1
 会选b，是因为优化使用b可以避免排序，代价更小
 如果改为 order by b,a limit 1则这个时候会按照预期选a
 3某些场景下，可以新建合适的索引，删除误用索引

 change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。
 merge过程-总结
 1从磁盘读数据
 2应用chagne buffer
 3写redo log
 这个数据还在内存中属于脏页，后续会有落盘动作